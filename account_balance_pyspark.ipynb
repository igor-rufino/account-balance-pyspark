{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicialização\n",
    "\n",
    "O script começa importando as bibliotecas necessárias e definindo os esquemas de leitura para os arquivos de saldo inicial e movimentações diárias.\n",
    "\n",
    "Uma sessão Spark é criada para permitir a leitura e processamento dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://host.docker.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>SaldoClientes</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2117f3efad0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "DATA_PATH = \"data/\"\n",
    "BALANCE_FILE = \"tabela_saldo_inicial.txt\"\n",
    "MOV_FILE = \"movimentacao_dia_{}.txt\"\n",
    "\n",
    "spark = SparkSession.builder.appName(\"SaldoClientes\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leitura dos Dados Iniciais\n",
    "\n",
    "O saldo inicial é lido de um arquivo CSV. O schema define os tipos de dados esperados para cada coluna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_saldo_inicial = \"Nome STRING, CPF STRING, Saldo_Inicial_CC FLOAT, data STRING\"\n",
    "schema_movimentacao = \"Nome STRING, CPF STRING, Movimentacao_dia FLOAT, data_mov STRING\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+----------------+----------+\n",
      "|   Nome|        CPF|Saldo_Inicial_CC|      data|\n",
      "+-------+-----------+----------------+----------+\n",
      "|  Maria|00000000001|          523.86|01/04/2022|\n",
      "|   José|00000000002|          917.78|01/04/2022|\n",
      "|   João|00000000003|          321.84|01/04/2022|\n",
      "|  Paulo|00000000004|          271.51|01/04/2022|\n",
      "|  Pedro|00000000005|          225.55|01/04/2022|\n",
      "|Antonio|00000000006|           875.5|01/04/2022|\n",
      "| Marcos|00000000007|          365.88|01/04/2022|\n",
      "|   Luiz|00000000008|          832.63|01/04/2022|\n",
      "| Arthur|00000000009|          221.12|01/04/2022|\n",
      "+-------+-----------+----------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "balance_df = spark.read.csv(f\"{DATA_PATH}{BALANCE_FILE}\", header=True, schema=schema_saldo_inicial, sep=\";\")\n",
    "balance_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparação do processamento e DataFrame de Saldo Final\n",
    "\n",
    "Inicia-se um DataFrame com o saldo inicial que será atualizado ao longo das movimentações diárias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data inicial\n",
    "initial_date_str = balance_df.select(\"data\").first()[0].replace('/', '_')\n",
    "initial_date = datetime.strptime(initial_date_str, \"%d_%m_%Y\")\n",
    "\n",
    "# Nome da coluna de saldo final atual\n",
    "current_balance_column = f\"Saldo_Final_{initial_date_str}\"\n",
    "\n",
    "# Inicializar o DataFrame final com saldo inicial\n",
    "final_df = balance_df.select([\"CPF\", \"Saldo_Inicial_CC\"]).withColumnRenamed(\"Saldo_Inicial_CC\", current_balance_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções de Processamento\n",
    "\n",
    "Duas funções são definidas para atualizar os saldos com base nas movimentações diárias e aplicar estornos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`atualizar_saldo`:\n",
    "\n",
    "Atualiza o saldo final com base nas movimentações diárias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para atualizar saldos com base nas movimentações diárias\n",
    "def atualizar_saldo(saldo_df, mov_df, current_balance_column, current_date_str):\n",
    "    movimentacao = mov_df.filter(F.col(f\"data_mov_{current_date_str}\") == current_date_str.replace('_', '/'))\n",
    "    mov_agrupada = movimentacao.groupBy(\"CPF\", f\"data_mov_{current_date_str}\").agg(F.sum(\"Movimentacao_dia\").alias(f\"Total_mov_{current_date_str}\")).orderBy(\"CPF\")\n",
    "\n",
    "    saldo_atualizado = saldo_df.join(mov_agrupada, on=\"CPF\", how=\"fullouter\").na.fill(0)\n",
    "    saldo_atualizado = saldo_atualizado.withColumn(\"Saldo_Final\", saldo_atualizado[current_balance_column] + saldo_atualizado[f\"Total_mov_{current_date_str}\"])\n",
    "\n",
    "    return saldo_atualizado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`aplicar_estornos`:\n",
    "\n",
    "Aplica estornos em movimentações de dias anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para aplicar estornos nas movimentações de dias anteriores\n",
    "def aplicar_estornos(saldo_df, mov_df, current_date_str):\n",
    "    estornos = mov_df.filter(F.col(f\"data_mov_{current_date_str}\") < current_date_str)\n",
    "    \n",
    "    for estorno_row in estornos.collect():\n",
    "        cpf = estorno_row['CPF']\n",
    "        estorno_date = estorno_row[f'data_mov_{current_date_str}']\n",
    "        estorno_valor = estorno_row['Movimentacao_dia']\n",
    "\n",
    "        estorno_balance_column = f\"Saldo_Final_{estorno_date.replace('/', '_')}\"\n",
    "\n",
    "        if estorno_balance_column in saldo_df.columns:\n",
    "            saldo_df = saldo_df.withColumn(\n",
    "                estorno_balance_column,\n",
    "                F.when(saldo_df[\"CPF\"] == cpf, saldo_df[estorno_balance_column] + estorno_valor)\n",
    "                .otherwise(saldo_df[estorno_balance_column])\n",
    "            )\n",
    "    return saldo_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processamento das Movimentações Diárias\n",
    "\n",
    "O script itera sobre os arquivos de movimentações diárias e aplica as atualizações de saldo e estornos conforme necessário de maneira dinâmica.\n",
    "\n",
    "O progresso das movimentações e estornos são atualizados e mostrados a cada iteração."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saldo final atualizado para o dia 02_04_2022:\n",
      "+-----------+----------------------+-------------------+--------------------+----------------------+\n",
      "|        CPF|Saldo_Final_01_04_2022|data_mov_02_04_2022|Total_mov_02_04_2022|Saldo_Final_02_04_2022|\n",
      "+-----------+----------------------+-------------------+--------------------+----------------------+\n",
      "|00000000001|                523.86|               NULL|                 0.0|     523.8599853515625|\n",
      "|00000000002|                917.78|               NULL|                 0.0|      917.780029296875|\n",
      "|00000000003|                321.84|               NULL|                 0.0|     321.8399963378906|\n",
      "|00000000004|                271.51|         02/04/2022|  241.61999130249023|     513.1300010681152|\n",
      "|00000000005|                225.55|         02/04/2022|    87.6300048828125|     313.1800079345703|\n",
      "|00000000006|                 875.5|         02/04/2022|   283.7699890136719|    1159.2699890136719|\n",
      "|00000000007|                365.88|         02/04/2022|   292.8600158691406|     658.7400207519531|\n",
      "|00000000008|                832.63|               NULL|                 0.0|     832.6300048828125|\n",
      "|00000000009|                221.12|               NULL|                 0.0|     221.1199951171875|\n",
      "|00000000010|                   0.0|         02/04/2022|   600.3499755859375|     600.3499755859375|\n",
      "+-----------+----------------------+-------------------+--------------------+----------------------+\n",
      "\n",
      "Saldo final atualizado para o dia 03_04_2022:\n",
      "+-----------+----------------------+-------------------+--------------------+----------------------+-------------------+--------------------+----------------------+\n",
      "|        CPF|Saldo_Final_01_04_2022|data_mov_02_04_2022|Total_mov_02_04_2022|Saldo_Final_02_04_2022|data_mov_03_04_2022|Total_mov_03_04_2022|Saldo_Final_03_04_2022|\n",
      "+-----------+----------------------+-------------------+--------------------+----------------------+-------------------+--------------------+----------------------+\n",
      "|00000000001|                523.86|               NULL|                 0.0|     523.8599853515625|         03/04/2022|   891.3200073242188|    1415.1799926757812|\n",
      "|00000000002|                917.78|               NULL|                 0.0|      917.780029296875|         03/04/2022|    548.930004119873|     1466.710033416748|\n",
      "|00000000003|                321.84|               NULL|                 0.0|     321.8399963378906|         03/04/2022| -309.27001190185547|    12.569984436035156|\n",
      "|00000000004|                271.51|         02/04/2022|  241.61999130249023|     513.1300010681152|               NULL|                 0.0|     513.1300010681152|\n",
      "|00000000005|                225.55|         02/04/2022|    87.6300048828125|    482.69000244140625|               NULL|                 0.0|    482.69000244140625|\n",
      "|00000000006|                 875.5|         02/04/2022|   283.7699890136719|     1320.489990234375|               NULL|                 0.0|     1320.489990234375|\n",
      "|00000000007|                365.88|         02/04/2022|   292.8600158691406|     792.4100189208984|               NULL|                 0.0|     792.4100189208984|\n",
      "|00000000008|                832.63|               NULL|                 0.0|     832.6300048828125|         03/04/2022|  190.36000061035156|    1022.9900054931641|\n",
      "|00000000009|                221.12|               NULL|                 0.0|     221.1199951171875|               NULL|                 0.0|     221.1199951171875|\n",
      "|00000000010|                   0.0|         02/04/2022|   600.3499755859375|     600.3499755859375|         03/04/2022|  -274.7400016784668|     325.6099739074707|\n",
      "|00000000011|                   0.0|               NULL|                 0.0|                   0.0|         03/04/2022|   768.3599853515625|     768.3599853515625|\n",
      "+-----------+----------------------+-------------------+--------------------+----------------------+-------------------+--------------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "number_of_files = len([file for file in os.listdir(DATA_PATH) if os.path.isfile(os.path.join(DATA_PATH, file))]) - 1\n",
    "\n",
    "# Iterar sobre os dias e processar as movimentações\n",
    "for i in range(1, number_of_files + 1):\n",
    "    current_date = initial_date + timedelta(days=i)\n",
    "    current_date_str = current_date.strftime(\"%d_%m_%Y\")\n",
    "    \n",
    "    current_mov_file = DATA_PATH + MOV_FILE.format(current_date_str)\n",
    "    \n",
    "    if os.path.exists(current_mov_file):\n",
    "        mov_df = spark.read.csv(current_mov_file, header=True, schema=schema_movimentacao, sep=\";\")\n",
    "        mov_df = mov_df.withColumnRenamed(\"data_mov\", f\"data_mov_{current_date_str}\")\n",
    "        \n",
    "        final_df = aplicar_estornos(final_df, mov_df, current_date_str)\n",
    "        final_df = atualizar_saldo(final_df, mov_df, current_balance_column, current_date_str)\n",
    "\n",
    "        current_balance_column = f\"Saldo_Final_{current_date_str}\"\n",
    "        \n",
    "        final_df = final_df.withColumnRenamed(\"Saldo_Final\", f\"Saldo_Final_{current_date_str}\")\n",
    "        print(f\"Saldo final atualizado para o dia {current_date_str}:\")\n",
    "        final_df.orderBy(\"CPF\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exibição do Resultado Final\n",
    "\n",
    "Após processar todos os arquivos, o saldo final acumulado é exibido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado final acumulado:\n",
      "+-----------+----------------------+\n",
      "|        CPF|Saldo_Final_03_04_2022|\n",
      "+-----------+----------------------+\n",
      "|00000000001|    1415.1799926757812|\n",
      "|00000000002|     1466.710033416748|\n",
      "|00000000003|    12.569984436035156|\n",
      "|00000000004|     513.1300010681152|\n",
      "|00000000005|    482.69000244140625|\n",
      "|00000000006|     1320.489990234375|\n",
      "|00000000007|     792.4100189208984|\n",
      "|00000000008|    1022.9900054931641|\n",
      "|00000000009|     221.1199951171875|\n",
      "|00000000010|     325.6099739074707|\n",
      "|00000000011|     768.3599853515625|\n",
      "+-----------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df = final_df.orderBy(\"CPF\")\n",
    "print(\"Resultado final acumulado:\")\n",
    "final_df.select(\"CPF\", f\"Saldo_Final_{current_date_str}\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encerramento da Sessão Spark\n",
    "\n",
    "A sessão Spark é encerrada para liberar os recursos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
